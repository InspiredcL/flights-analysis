{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Notebook\n",
    "\n",
    "Desarrollamos en un notebook local para analizar el procedimiento a seguir\n",
    "para guardar la tabla en un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar paquetes\n",
    "Podemos utilizar funciones mágicas de los Jupyter Notebooks (ipython) para\n",
    "instalar los paquetes necesarios, ya que asi nos aseguramos que estos sean\n",
    "instalados en el ambiente correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pandas-gbq 'google-cloud-bigquery[bqstorage,pandas]'\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bigframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/inspired/data-science-on-gcp/dsongcp/bin/python3\n"
     ]
    }
   ],
   "source": [
    "!which python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Desarrollo en notebook local.\n",
    "\n",
    "Desarrollamos en un notebook local para analizar el procedimiento a seguir\n",
    "para guardar la tabla en un archivo\n",
    "\"\"\"\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import bigframes.pandas as bpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultar en Bigquery\n",
    "\n",
    "Para hacer consultas en BiQuery y guardarlas en un dataframe en python podemos\n",
    "emplear 3 métodos que prácticamente son lo mismo:\n",
    "\n",
    "1. Llamadas a BigQuery utilizando la API de python:\n",
    "   Primero creamos el objeto cliente de BigQuery usando su constructor\n",
    "   Client() luego usamos métodos de ese cliente para lo necesario, en\n",
    "   este caso utilizamos el método query_and_wait y luego al iterador\n",
    "   devuelto le aplicamos el método to_dataframe.\n",
    "\n",
    "2. Módulo pandas_gbq:\n",
    "   El cual proporciona una envoltura para el servicio web de análisis\n",
    "   BigQuery de Google, en este caso utilizamos la función read_gbq del módulo.\n",
    "\n",
    "3. Line magics o Cell magics\n",
    "   Acá las lineas o celdas de magia son funciones de ipython que se pueden\n",
    "   llamar con un estilo similar al sintaxis de la linea de comandos, si la\n",
    "   función no es predefinida debemos cargarla si estamos en nuestro entorno\n",
    "   local utilizando el nombre de la extensión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternativas de descarga:\n",
    "\n",
    "Se definen las variables a utilizar en las alternativas como el string de\n",
    "la consulta y otras según sea necesario para el tipo de consulta.\n",
    "\n",
    "En este caso solamente definimos el string de la consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM bigquery-manu-407202.dsongcp.flights\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternativa 1 - Llamadas a BigQuery\n",
    "\n",
    "Creamos el objeto cliente y ejecutamos la consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "# query retorna QueryJob\n",
    "q_result = client.query(SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = q_result.to_dataframe(date_dtype=pd.StringDtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Alternativa Opcional]\n",
    "query_and_wait retorna RowIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_result_wait = client.query_and_wait(SQL)\n",
    "df = q_result_wait.to_dataframe(date_dtype=pd.StringDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = client.query_and_wait(SQL).to_dataframe(date_dtype=pd.StringDtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los DataFrames de manera separada para evitar sobrecargar la\n",
    "memoria local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problemas con formato de fecha queda como datetime\n",
    "df_bq = q_result.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problemas con formato de fecha queda como date\n",
    "df_bq_date = q_result.to_dataframe(date_dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcto como str\n",
    "df_bq_string_date = q_result.to_dataframe(date_dtype=pd.StringDtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternativa 2 - Pandas Google Big Query\n",
    "\n",
    "Utilizamos read_gbq para leer la consulta directamente en un DataFrame con\n",
    "la opción de use_bqstorage_api en True para utilizar la API de\n",
    "BigQuery Storage y así obtener resultados grandes en menor tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportAssignmentType = false\n",
    "df_bq_pandas: pd.DataFrame = pandas_gbq.read_gbq(SQL, use_bqstorage_api=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternativa 3 - Jupyter Magic\n",
    "\n",
    "El sintaxis de la celda mágica es el siguiente:\n",
    "\n",
    "```\n",
    "%%bigquery [<destination_var>] [--project <project>] [--use_legacy_sql]\n",
    "           [--verbose] [--params <params>] <query>\n",
    "```\n",
    "\n",
    "Obs. si nos encontramos en un ambiente local, antes de ejecutar la celda\n",
    "debemos ejecutar la linea mágica load_ext la cual carga las funciones\n",
    "mágicas por su nombre de módulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df_bq_magic\n",
    "SELECT\n",
    "    *\n",
    "FROM bigquery-manu-407202.dsongcp.flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos el esquema de la tabla flights y borramos los campos extras\n",
    "que describen la tabla, utilizamos show para mostrar información de un\n",
    "recurso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq show --format=prettyjson dsongcp.flights > flights_schema.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer archivos descargados desde la consola\n",
    "\n",
    "Leemos los archivos descargados desde la consola de google cloud platform\n",
    "para comparar los formatos y que debemos cambiar.\n",
    "\n",
    "Obs. dependiendo del motor para leer los archivos ya sea `ujson` o `pyarrow`\n",
    "los tipos de datos serán distintos, esto también depende del back-end de\n",
    "tipos de datos `numpy_nullable` retorna un DataFrame y `pyarrow` retorna\n",
    "ArrowDtype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba archivo json pequeño `flights_few_lines.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 flights/flights_console.json > flights/flights_few_lines.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportCallIssue = false\n",
    "df_few_json = pd.read_json(\"flights/flights_few_lines.json\",\n",
    "                               orient=\"records\",\n",
    "                               lines=True,\n",
    "                               engine=\"pyarrow\"\n",
    "                               )\n",
    "df_few_json.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo json `flights_console.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportCallIssue = false\n",
    "df_console_json = pd.read_json(\"flights/flights_console.json\",\n",
    "                               orient=\"records\",\n",
    "                               lines=True,\n",
    "                               engine=\"pyarrow\"\n",
    "                               )\n",
    "df_console_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_console_json_10=df_console_json.head(10)\n",
    "df_console_json_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba archivo csv pequeño `flights_few_lines.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 flights/flights_console.csv > flights/flights_few_lines.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_console_csv_fl = pd.read_csv(\"flights/flights_few_lines.csv\")\n",
    "df_console_csv_fl.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo `flights_console.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_console_csv = pd.read_csv(\"flights/flights_console.csv\")\n",
    "df_console_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escribir a un archivo local\n",
    "\n",
    "Escribimos a un archivo local después de analizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos probando si escribiendo a los archivos con pocos datos nos\n",
    "otorga buenos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = df.head(10)\n",
    "json = df_10.to_json(\n",
    "    \"flights/flights_10.jsonl\",\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribimos a un archivo local después de analizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = df.to_json(\n",
    "    \"flights/flights.json\",\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 300000  # Define el tamaño de cada trozo\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    chunk = df[i:i + chunk_size]\n",
    "    chunk.to_json(f\"flights/chunks/flights_{i}.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 300000  # Define el tamaño de cada trozo\n",
    "num_chunks = len(df) // chunk_size + 1  # Calcula el número total de trozos\n",
    "\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    chunk = df[i:i + chunk_size]\n",
    "    chunk.to_json(\n",
    "        f\"flights/chunks/flights_{str(i // chunk_size).zfill(5)}-of-{str(num_chunks).zfill(5)}.jsonl\",\n",
    "        orient=\"records\",\n",
    "        lines=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bq_10 = df_bq.head(10)\n",
    "json = df_bq_10.to_json(\n",
    "    \"flights/df_bq_10.json\",\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bq_date_10 = df_bq_date.head(10)\n",
    "json = df_bq_date_10.to_json(\n",
    "    \"flights/df_bq_date_10.json\",\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bq_string_date_10 = df_bq_string_date.head(10)\n",
    "json = df_bq_string_date_10.to_json(\n",
    "    \"flights/df_bq_string_date_10.json\",\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Alternativa Opcional] Modificaciones\n",
    "Hacemos los cambios correspondientes, si es que no especificamos al momento de\n",
    "transformar a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bq[\"FL_DATE\"] = pd.to_datetime(df_bq[\"FL_DATE\"])\n",
    "df_bq[\"FL_DATE\"] = df_bq[\"FL_DATE\"].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Test\n",
    "not_string_cols = ['FL_DATE', 'DEP_DELAY', 'TAXI_OUT',\n",
    "                   'TAXI_IN', 'ARR_DELAY', 'CANCELLED', 'DIVERTED']\n",
    "string_cols = [col for col in df_bq.columns if col not in not_string_cols]\n",
    "for col in string_cols:\n",
    "    df_bq[col] = df_bq[col].astype(str)\n",
    "\n",
    "# Completar con ceros a la izquierda las columnas con formato \"hhmm\"\n",
    "for col in [\"CRS_DEP_TIME\", \"DEP_TIME\", \"WHEELS_OFF\", \"WHEELS_ON\", \"CRS_ARR_TIME\", \"ARR_TIME\"]:\n",
    "    df_bq[col] = df_bq[col].str.zfill(4)\n",
    "\n",
    "# Eliminamos los vuelos cancelados y desviados con fines de desarrollo\n",
    "df_bq = df_bq.loc[~df_bq[\"DIVERTED\"] & ~df_bq[\"CANCELLED\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desarrollo airports\n",
    "para el archivo `airports_2024`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv(\"airports_2024.csv\")\n",
    "airports_tz = df_csv.iloc[:, [0, 21, 26]]\n",
    "airports_tz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsongcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
